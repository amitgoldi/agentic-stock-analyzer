# Tavily API Configuration
TAVILY_API_KEY=your_tavily_api_key_here

# LiteLLM Configuration (for custom LLM proxy)
# Use these settings if you're using LiteLLM proxy
LITELLM_BASE_URL=http://litellm.litellm.svc.cluster.local:4000
LITELLM_API_KEY=sk-wandlitellm

# Standard AI Provider Configuration (alternative to LiteLLM)
# Uncomment and use these if you're using direct API access instead of LiteLLM
# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Application Configuration
DEBUG=false
LOG_LEVEL=INFO

# Agent Model Configuration
# For LiteLLM, use the model name as configured in your LiteLLM proxy
# Common LiteLLM model formats: gpt-4, gpt-4.1, gpt-3.5-turbo, claude-3-sonnet, etc.
AGENT_MODEL=gpt-4.1
AGENT_TEMPERATURE=0.1
AGENT_MAX_RETRIES=3

# Tavily Search Configuration
TAVILY_MAX_RESULTS=10
TAVILY_SEARCH_DEPTH=advanced